{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohvOaBZiP2hZ"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IngCarlaPezzone/tensorflow-1-public/blob/main/C1/W4/ungraded_labs/C1_W4_Lab_3_compacted_images_traducido.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUhkElcjP2hf"
      },
      "outputs": [],
      "source": [
        "# # Instale este paquete para utilizar la GPU de Colab para el entrenamiento\n",
        "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXZT2UsyIVe_"
      },
      "outputs": [],
      "source": [
        "# Training data\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/horse-or-human.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mLij6qde6Ox"
      },
      "outputs": [],
      "source": [
        "# Validation data\n",
        "!wget https://storage.googleapis.com/tensorflow-1-public/course2/week3/validation-horse-or-human.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLy3pthUS0D2"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "# Unzip\n",
        "local_zip = './horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./horse-or-human')\n",
        "\n",
        "local_zip = './validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('./validation-horse-or-human')\n",
        "\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NR_M9nWN-K8B"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "train_horse_dir = os.path.join('./horse-or-human/horses')\n",
        "train_human_dir = os.path.join('./horse-or-human/humans')\n",
        "validation_horse_dir = os.path.join('./validation-horse-or-human/horses')\n",
        "validation_human_dir = os.path.join('./validation-horse-or-human/humans')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bOeNBIZP2hk"
      },
      "outputs": [],
      "source": [
        "train_horse_names = os.listdir(train_horse_dir)\n",
        "print(f'TRAIN SET HORSES: {train_horse_names[:10]}')\n",
        "\n",
        "train_human_names = os.listdir(train_human_dir)\n",
        "print(f'TRAIN SET HUMANS: {train_human_names[:10]}')\n",
        "\n",
        "validation_horse_hames = os.listdir(validation_horse_dir)\n",
        "print(f'VAL SET HORSES: {validation_horse_hames[:10]}')\n",
        "\n",
        "validation_human_names = os.listdir(validation_human_dir)\n",
        "print(f'VAL SET HUMANS: {validation_human_names[:10]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTpdVrBg2LZC"
      },
      "outputs": [],
      "source": [
        "print(f'total training horse images: {len(os.listdir(train_horse_dir))}')\n",
        "print(f'total training human images: {len(os.listdir(train_human_dir))}')\n",
        "print(f'total validation horse images: {len(os.listdir(validation_horse_dir))}')\n",
        "print(f'total validation human images: {len(os.listdir(validation_human_dir))}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PixZ2s5QbYQ3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # 0 == 'horse'. 1 == 'human'\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClebU9NJg99G"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#  Normalization\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flujo de imágenes de entrenamiento en lotes de 128 utilizando el generador train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './horse-or-human/',  #  Este es el directorio de origen para las imágenes de entrenamiento\n",
        "        target_size=(150, 150),  # Todas las imágenes serán redimensionadas a 150x150\n",
        "        batch_size=128,\n",
        "        # Como se ha utilizado la pérdida binaria_crossentropy, se necesitan etiquetas binarias\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flujo de imágenes de entrenamiento en lotes de 128 utilizando el generador train_datagen\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        './validation-horse-or-human/',  # Este es el directorio de origen para las imágenes de entrenamiento\n",
        "        target_size=(150, 150),  # Todas las imágenes se redimensionarán a 150x150\n",
        "        batch_size=32,\n",
        "        # Como se ha utilizado la pérdida binaria_crossentropy, se necesitan etiquetas binarias\n",
        "        class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb1_lgobv81m"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=15,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoWp43WxJDNT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "    # predicting images\n",
        "    path = '/content/' + fn\n",
        "    img = image.load_img(path, target_size=(150, 150))\n",
        "    x = image.img_to_array(img)\n",
        "    x /= 255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "\n",
        "    images = np.vstack([x])\n",
        "    classes = model.predict(images, batch_size=10)\n",
        "    print(classes[0])\n",
        "    if classes[0]>0.5:\n",
        "      print(fn + \" is a human\")\n",
        "    else:\n",
        "      print(fn + \" is a horse\")\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5tES8rXFjux"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Definir un nuevo modelo que tomará una imagen como entrada, y emitirá\n",
        "# representaciones intermedias para todas las capas del modelo anterior después de\n",
        "# la primera.\n",
        "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
        "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
        "\n",
        "# Prepara una imagen de entrada aleatoria del conjunto de entrenamiento.\n",
        "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
        "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
        "img_path = random.choice(horse_img_files + human_img_files)\n",
        "img = load_img(img_path, target_size=(150, 150))  # esta es una imagen PIL\n",
        "x = img_to_array(img)  # matriz Numpy con forma (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Matriz Numpy con forma (1, 150, 150, 3)\n",
        "\n",
        "# Escala por  1/255\n",
        "x /= 255\n",
        "\n",
        "# Pasar la imagen por la red, obteniendo así todas\n",
        "# representaciones intermedias de esta imagen.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# Estos son los nombres de las capas, por lo que puede tenerlos como parte de la trama\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "# Visualizar las representaciones\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "    if len(feature_map.shape) == 4:\n",
        "\n",
        "    # Sólo se hace esto para las capas conv / maxpool, no para las capas totalmente conectadas\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "\n",
        "    # El mapa de características tiene forma (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "\n",
        "    # Mosaico de las imágenes en esta matriz\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "        x = feature_map[0, :, :, i]\n",
        "        x -= x.mean()\n",
        "        x /= x.std()\n",
        "        x *= 64\n",
        "        x += 128\n",
        "        x = np.clip(x, 0, 255).astype('uint8')\n",
        "\n",
        "        # Colocar cada filtro en esta gran cuadrícula horizontal\n",
        "        display_grid[:, i * size : (i + 1) * size] = x\n",
        "\n",
        "    # Mostrar la grilla\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "651IgjLyo-Jx"
      },
      "outputs": [],
      "source": [
        "# Terminate the kernel and free memory resources\n",
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}